# ClasificaciÃ³n de ImÃ¡genes Satelitales

Sistema completo de clasificaciÃ³n de imÃ¡genes satelitales utilizando redes neuronales convolucionales (CNN) para clasificar imÃ¡genes en 4 categorÃ­as: nubes, desierto, Ã¡reas verdes y agua.

## ðŸ“‹ Tabla de Contenidos

- [DescripciÃ³n del Proyecto](#descripciÃ³n-del-proyecto)
- [Dataset](#dataset)
- [Arquitecturas de Modelos](#arquitecturas-de-modelos)
- [MetodologÃ­a de Entrenamiento](#metodologÃ­a-de-entrenamiento)
- [Resultados](#resultados)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Requisitos e InstalaciÃ³n](#requisitos-e-instalaciÃ³n)
- [Uso](#uso)

---

## ðŸ“– DescripciÃ³n del Proyecto

Este proyecto implementa un sistema de clasificaciÃ³n de imÃ¡genes satelitales utilizando dos arquitecturas diferentes de redes neuronales convolucionales (CNN). El objetivo es comparar el desempeÃ±o de ambas arquitecturas mediante validaciÃ³n cruzada y seleccionar el mejor modelo para la clasificaciÃ³n final.

**Clases a clasificar:**
- â˜ï¸ **Cloudy** (Nubes)
- ðŸœï¸ **Desert** (Desierto)
- ðŸŒ¿ **Green Area** (Ãrea Verde)
- ðŸ’§ **Water** (Agua)

---

## ðŸ“Š Dataset

### InformaciÃ³n del Dataset

El dataset contiene **5,631 imÃ¡genes satelitales** distribuidas en 4 clases:

| Clase | Cantidad de ImÃ¡genes |
|-------|---------------------|
| `cloudy` | 1,500 |
| `desert` | 1,131 |
| `green_area` | 1,500 |
| `water` | 1,500 |
| **Total** | **5,631** |

**Fuente del Dataset:** [Kaggle - Satellite Image Classification](https://www.kaggle.com/datasets/mahmoudreda55/satellite-image-classification)

### Preprocesamiento

- **TamaÃ±o de imagen**: Todas las imÃ¡genes se redimensionan a **256x256 pÃ­xeles**
- **NormalizaciÃ³n**: Los valores de pÃ­xeles se normalizan al rango [0, 1] dividiendo por 255
- **ConversiÃ³n a RGB**: Las imÃ¡genes se convierten al formato RGB si estÃ¡n en otro espacio de color

---

## ðŸ§  Arquitecturas de Modelos

Se implementaron y compararon dos arquitecturas CNN diferentes:

### CNN 1: Red Simple

Esta arquitectura utiliza capas convolucionales bÃ¡sicas con pooling y dropout para regularizaciÃ³n.

**Estructura:**
```
Input (256x256x3)
  â†“
Conv2D(32 filters, 3x3) + ReLU
  â†“
MaxPooling2D(2x2)
  â†“
Conv2D(64 filters, 3x3) + ReLU
  â†“
MaxPooling2D(2x2)
  â†“
Conv2D(128 filters, 3x3) + ReLU
  â†“
MaxPooling2D(2x2)
  â†“
Conv2D(128 filters, 3x3) + ReLU
  â†“
MaxPooling2D(2x2)
  â†“
Flatten
  â†“
Dropout(0.5)
  â†“
Dense(512) + ReLU
  â†“
Dense(4) + Softmax
```

**CaracterÃ­sticas:**
- 4 bloques convolucionales progresivos (32 â†’ 64 â†’ 128 â†’ 128 filtros)
- Pooling despuÃ©s de cada bloque convolucional para reducir dimensiones
- Dropout del 50% antes de la capa densa final para prevenir overfitting
- Capa de salida con 4 neuronas (una por clase) y activaciÃ³n softmax

**Optimizador:** Adam  
**FunciÃ³n de pÃ©rdida:** Categorical Crossentropy  
**MÃ©tricas:** Accuracy

---

### CNN 2: Red con Batch Normalization

Esta arquitectura es mÃ¡s compleja y utiliza tÃ©cnicas avanzadas como Batch Normalization y mÃºltiples capas de dropout estratÃ©gicamente colocadas.

**Estructura:**
```
Input (256x256x3)
  â†“
Conv2D(32 filters, 3x3) + ReLU
  â†“
BatchNormalization
  â†“
Conv2D(32 filters, 3x3) + ReLU
  â†“
MaxPooling2D(2x2)
  â†“
Dropout(0.25)
  â†“
Conv2D(64 filters, 3x3) + ReLU
  â†“
BatchNormalization
  â†“
Conv2D(64 filters, 3x3) + ReLU
  â†“
MaxPooling2D(2x2)
  â†“
Dropout(0.25)
  â†“
Conv2D(128 filters, 3x3) + ReLU
  â†“
BatchNormalization
  â†“
Conv2D(128 filters, 3x3) + ReLU
  â†“
MaxPooling2D(2x2)
  â†“
Dropout(0.25)
  â†“
Conv2D(256 filters, 3x3) + ReLU
  â†“
BatchNormalization
  â†“
MaxPooling2D(2x2)
  â†“
Dropout(0.25)
  â†“
Flatten
  â†“
Dense(512) + ReLU
  â†“
BatchNormalization
  â†“
Dropout(0.5)
  â†“
Dense(256) + ReLU
  â†“
Dropout(0.5)
  â†“
Dense(4) + Softmax
```

**CaracterÃ­sticas:**
- **Bloques convolucionales dobles**: Cada nivel tiene dos capas convolucionales antes del pooling
- **Batch Normalization**: DespuÃ©s de cada capa convolucional y en la capa densa intermedia para estabilizar el entrenamiento
- **Dropout progresivo**: 25% en capas convolucionales, 50% en capas densas
- **MÃ¡s filtros**: ProgresiÃ³n 32 â†’ 64 â†’ 128 â†’ 256 filtros
- **MÃ¡s capas densas**: Dos capas densas (512 y 256 neuronas) en lugar de una

**Optimizador:** Adam  
**FunciÃ³n de pÃ©rdida:** Categorical Crossentropy  
**MÃ©tricas:** Accuracy

---

## ðŸ”¬ MetodologÃ­a de Entrenamiento

### Proceso de Entrenamiento

El entrenamiento se realiza en **3 etapas principales**:

#### Etapa 1: ParticiÃ³n de Datos

1. **DivisiÃ³n Train/Test**: 
   - **80%** de los datos â†’ Conjunto de entrenamiento (`train/`)
   - **20%** de los datos â†’ Conjunto de prueba (`test/`)
   - DivisiÃ³n estratificada por clase
   - Semilla aleatoria fija (random_state=42) para reproducibilidad

2. **DistribuciÃ³n de imÃ¡genes**:
   - **Training**: ~4,505 imÃ¡genes
   - **Testing**: ~1,126 imÃ¡genes

#### Etapa 2: ValidaciÃ³n Cruzada (Cross-Validation)

Se realiza **validaciÃ³n cruzada de 3 folds (3-Fold Cross-Validation)** para cada arquitectura:

1. **ParticiÃ³n de datos de entrenamiento**:
   - Los datos de entrenamiento se dividen en 3 folds
   - Cada fold se usa una vez como conjunto de validaciÃ³n
   - Los otros 2 folds se usan para entrenar

2. **Entrenamiento por fold**:
   - **Ã‰pocas por fold**: 10 Ã©pocas
   - **Batch size**: 32
   - **MÃ©trica evaluada**: Accuracy en el conjunto de validaciÃ³n

3. **CÃ¡lculo de mÃ©tricas**:
   - Se calcula la accuracy promedio de los 3 folds
   - Se calcula la desviaciÃ³n estÃ¡ndar para medir la consistencia
   - Resultado: `Accuracy promedio Â± DesviaciÃ³n estÃ¡ndar`

4. **SelecciÃ³n del mejor modelo**:
   - Se compara la accuracy promedio de CNN1 vs CNN2
   - El modelo con mayor accuracy promedio es seleccionado

#### Etapa 3: Entrenamiento Final y EvaluaciÃ³n

1. **Entrenamiento del modelo seleccionado**:
   - Se entrena con **todo el conjunto de entrenamiento** (sin dividir)
   - **Ã‰pocas**: 20 Ã©pocas
   - **Batch size**: 32
   - Sin conjunto de validaciÃ³n (ya se validÃ³ en la etapa anterior)

2. **Guardado del modelo**:
   - El modelo se guarda en formato `.h5` (HDF5)
   - Ruta: `modelos/best_model.h5` o raÃ­z del proyecto

3. **EvaluaciÃ³n en conjunto de prueba**:
   - Se evalÃºa el modelo en el conjunto de test (nunca visto durante el entrenamiento)
   - Se calculan las siguientes mÃ©tricas:
     - **Accuracy**: PrecisiÃ³n general
     - **Precision**: PrecisiÃ³n por clase (weighted average)
     - **Recall**: Sensibilidad por clase (weighted average)
     - **F1-Score**: Media armÃ³nica de precisiÃ³n y recall (weighted average)
   - Se genera la **matriz de confusiÃ³n**
   - Se generan visualizaciones de ejemplos correctos e incorrectos

### ConfiguraciÃ³n del Entrenamiento

| ParÃ¡metro | Valor |
|-----------|-------|
| TamaÃ±o de imagen | 256x256 pÃ­xeles |
| Batch size | 32 |
| Ã‰pocas (validaciÃ³n cruzada) | 10 |
| Ã‰pocas (entrenamiento final) | 20 |
| Folds (validaciÃ³n cruzada) | 3 |
| Optimizador | Adam |
| FunciÃ³n de pÃ©rdida | Categorical Crossentropy |
| MÃ©trica principal | Accuracy |

---

## ðŸ“ˆ Resultados

### Visualizaciones Generadas

El proceso genera varios archivos de visualizaciÃ³n y anÃ¡lisis:

#### 1. Matriz de ConfusiÃ³n (`confusion_matrix.png`)

Muestra la distribuciÃ³n de predicciones vs etiquetas reales:
- Diagonal principal: Predicciones correctas
- Fuera de la diagonal: Errores de clasificaciÃ³n
- Permite identificar quÃ© clases se confunden mÃ¡s entre sÃ­

#### 2. Predicciones Correctas (`correct_predictions.png`)

Muestra 5 ejemplos de imÃ¡genes correctamente clasificadas:
- Se selecciona al menos un ejemplo de cada clase (si es posible)
- Muestra la etiqueta real, la predicha y el nivel de confianza

#### 3. Predicciones Incorrectas (`incorrect_predictions.png`)

Muestra 5 ejemplos de imÃ¡genes mal clasificadas:
- Permite analizar los casos mÃ¡s difÃ­ciles
- Muestra la etiqueta real, la predicha (incorrecta) y el nivel de confianza

### InterpretaciÃ³n de Resultados

#### Confianza (Confidence Score)

El valor de confianza indica quÃ© tan seguro estÃ¡ el modelo de su predicciÃ³n:
- **0.0 - 1.0**: Probabilidad de que la predicciÃ³n sea correcta
- **> 0.9**: Muy confiado
- **0.7 - 0.9**: Moderadamente confiado
- **0.5 - 0.7**: Poca confianza
- **< 0.5**: Muy poco confiado (posible confusiÃ³n entre clases)

**Ejemplo:** Si `Conf: 0.66`, significa que el modelo estÃ¡ 66% seguro de su predicciÃ³n.

#### MÃ©tricas de EvaluaciÃ³n

- **Accuracy**: ProporciÃ³n de predicciones correctas sobre el total
- **Precision**: De todas las predicciones de una clase, cuÃ¡ntas fueron correctas
- **Recall**: De todas las instancias reales de una clase, cuÃ¡ntas fueron detectadas
- **F1-Score**: Balance entre precision y recall (media armÃ³nica)

---

## ðŸ“ Estructura del Proyecto

```
ModeloCompu2/
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ modelo.ipynb                # Notebook para Google Colab (con descarga automÃ¡tica)
â”‚
â”œâ”€â”€ best_model.h5               # Modelo entrenado final (guardado)
â”œâ”€â”€ confusion_matrix.png        # Matriz de confusiÃ³n generada
â”œâ”€â”€ correct_predictions.png     # Ejemplos de predicciones correctas
â”œâ”€â”€ incorrect_predictions.png   # Ejemplos de predicciones incorrectas
â”‚
â”œâ”€â”€ dataset/                    # Dataset local
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ cloudy/            # 1,500 imÃ¡genes
â”‚       â”œâ”€â”€ desert/            # 1,131 imÃ¡genes
â”‚       â”œâ”€â”€ green_area/        # 1,500 imÃ¡genes
â”‚       â””â”€â”€ water/             # 1,500 imÃ¡genes
â”‚
â”œâ”€â”€ train/                      # Se crea automÃ¡ticamente (80% datos)
â”‚   â”œâ”€â”€ cloudy/
â”‚   â”œâ”€â”€ desert/
â”‚   â”œâ”€â”€ green_area/
â”‚   â””â”€â”€ water/
â”‚
â”œâ”€â”€ test/                       # Se crea automÃ¡ticamente (20% datos)
â”‚   â”œâ”€â”€ cloudy/
â”‚   â”œâ”€â”€ desert/
â”‚   â”œâ”€â”€ green_area/
â”‚   â””â”€â”€ water/
```

---

## ðŸ“¦ Requisitos e InstalaciÃ³n

### Dependencias Python

```bash
pip install tensorflow scikit-learn matplotlib seaborn numpy pandas pillow
```

Para el notebook de Colab, tambiÃ©n necesitas:
```bash
pip install kagglehub
```

### Requisitos del Sistema

- **Python**: 3.7 o superior
- **TensorFlow**: 2.x
- **Memoria RAM**: MÃ­nimo 8GB recomendado
- **GPU**: Opcional pero altamente recomendada para acelerar el entrenamiento
  - CUDA compatible para TensorFlow GPU
  - O usar Google Colab con GPU T4 (gratis)

---

## ðŸš€ Uso

### OpciÃ³n 1: Entrenamiento Local (Script Python)

1. **Preparar el dataset**:
   - AsegÃºrate de que el dataset estÃ© en `dataset/data/` con las 4 carpetas de clases

2. **Ejecutar el script**:
   ```bash
   python entrenar_modelo.py
   ```
   
   O con permisos de ejecuciÃ³n:
   ```bash
   ./entrenar_modelo.py
   ```

3. **El script ejecutarÃ¡ automÃ¡ticamente**:
   - ParticiÃ³n de datos (train/test)
   - ValidaciÃ³n cruzada de ambas arquitecturas
   - SelecciÃ³n del mejor modelo
   - Entrenamiento final
   - EvaluaciÃ³n y generaciÃ³n de visualizaciones

### OpciÃ³n 2: Entrenamiento en Google Colab (Notebook)

1. Abre `modelo.ipynb` en Google Colab
2. Activa GPU: **Runtime â†’ Change runtime type â†’ GPU â†’ T4**
3. Ejecuta todas las celdas en orden
4. El notebook descargarÃ¡ automÃ¡ticamente el dataset desde Kaggle

### Uso del Modelo Entrenado

Para cargar y usar el modelo entrenado:

```python
import tensorflow as tf
from tensorflow import keras

# Cargar el modelo
model = keras.models.load_model('best_model.h5')

# Predecir una imagen
from PIL import Image
import numpy as np

# Cargar y preprocesar imagen
img = Image.open('ruta/a/imagen.jpg')
img = img.resize((256, 256))
img_array = np.array(img) / 255.0
img_array = np.expand_dims(img_array, axis=0)

# Predecir
predictions = model.predict(img_array)
predicted_class_idx = np.argmax(predictions[0])
confidence = np.max(predictions[0])

# Clases
CLASSES = ['cloudy', 'desert', 'green_area', 'water']
print(f"PredicciÃ³n: {CLASSES[predicted_class_idx]} (Confianza: {confidence:.2%})")
```

---

## ðŸ“ Notas TÃ©cnicas

### Preprocesamiento de ImÃ¡genes

- Todas las imÃ¡genes se convierten a RGB antes del procesamiento
- Las imÃ¡genes en escala de grises se convierten a RGB duplicando los canales
- Las imÃ¡genes con canal alpha (RGBA) se convierten a RGB descartando el canal alpha

### Optimizaciones de Memoria

- El script usa `ImageDataGenerator` para cargar imÃ¡genes en lotes y evitar cargar todo el dataset en memoria
- Se limpia la sesiÃ³n de TensorFlow despuÃ©s de cada fold en la validaciÃ³n cruzada
- Se eliminan temporalmente las carpetas de cada fold despuÃ©s de su evaluaciÃ³n

### Reproducibilidad

- Se usa `random_state=42` en todas las divisiones de datos
- Las semillas aleatorias estÃ¡n fijas para garantizar resultados reproducibles

---

## ðŸ” AnÃ¡lisis de Errores Comunes

### Casos de ConfusiÃ³n Frecuentes

Basado en los ejemplos de predicciones incorrectas, las clases que pueden confundirse son:

- **Water â†” Green Area**: Ãreas verdes cerca del agua pueden confundir al modelo
- **Desert â†” Cloudy**: Colores similares en ciertas condiciones de iluminaciÃ³n

### Factores que Afectan la PrecisiÃ³n

1. **Calidad de la imagen**: ResoluciÃ³n, contraste, iluminaciÃ³n
2. **Transiciones**: ImÃ¡genes en los bordes entre dos clases
3. **Condiciones atmosfÃ©ricas**: Nubes que cubren parcialmente otras Ã¡reas
4. **Ãngulo de visiÃ³n**: Perspectiva satelital diferente

---

## ðŸ“š Referencias

- [TensorFlow Documentation](https://www.tensorflow.org/)
- [Keras Documentation](https://keras.io/)
- [Scikit-learn Cross-Validation](https://scikit-learn.org/stable/modules/cross_validation.html)
- [Dataset: Satellite Image Classification](https://www.kaggle.com/datasets/mahmoudreda55/satellite-image-classification)

---

## ðŸ“„ Licencia

Este proyecto es de carÃ¡cter educativo/acadÃ©mico. El dataset utilizado pertenece a su respectivo propietario en Kaggle.

---

**Autor:** Proyecto de ComputaciÃ³n 2  
**Fecha:** 2024  
**PropÃ³sito:** ClasificaciÃ³n de imÃ¡genes satelitales utilizando CNN

